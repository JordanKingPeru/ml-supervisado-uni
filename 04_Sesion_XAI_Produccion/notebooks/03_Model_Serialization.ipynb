{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca2834e",
   "metadata": {},
   "source": [
    "# üíæ Sesi√≥n 04: Serializaci√≥n de Modelos - Del Notebook a Producci√≥n\n",
    "\n",
    "## üìë √çndice\n",
    "1.  [¬øPor Qu√© Serializar?](#1.-¬øPor-Qu√©-Serializar?) ü§î\n",
    "2.  [Nivel 1: Pickle (Lo B√°sico)](#2.-Nivel-1:-Pickle) ü•í\n",
    "3.  [Nivel 2: Joblib (El Est√°ndar ML)](#3.-Nivel-2:-Joblib) üì¶\n",
    "4.  [Nivel 3: ONNX (Interoperabilidad)](#4.-Nivel-3:-ONNX) üåê\n",
    "5.  [Nivel 4: PMML (Legacy Enterprise)](#5.-Nivel-4:-PMML) üè¢\n",
    "6.  [Nivel 5: Formatos Nativos](#6.-Nivel-5:-Formatos-Nativos) üéØ\n",
    "7.  [Comparativa Final](#7.-Comparativa-Final) üìä\n",
    "8.  [Micro-Desaf√≠o](#8.-üß†-Micro-Desaf√≠o) üß†\n",
    "\n",
    "## üíº Caso de Negocio: El Modelo que Nadie Pudo Desplegar\n",
    "**Contexto:**\n",
    "Tu modelo de Credit Scoring tiene un AUC de 0.98. ¬°El Gerente est√° feliz!\n",
    "Pero llega el equipo de Infraestructura y pregunta: *\"¬øEn qu√© formato est√°? Nuestra API est√° en Java, el frontend en JavaScript, y el sistema legacy en C++.\"*\n",
    "\n",
    "**El Problema:**\n",
    "El modelo est√° en un `.pkl` de Python. Solo funciona si tienes **exactamente** la misma versi√≥n de Python, Scikit-Learn y LightGBM. En otro lenguaje... simplemente **no carga**.\n",
    "\n",
    "**Tu Misi√≥n:**\n",
    "Aprender **5 formas de serializar** modelos, desde la m√°s simple hasta la m√°s portable, para que tu modelo pueda desplegarse **en cualquier entorno**.\n",
    "\n",
    "## üéØ Objetivos de Aprendizaje\n",
    "| Nivel | Objetivo |\n",
    "|-------|----------|\n",
    "| üü¢ B√°sico | Entender Pickle y Joblib para entornos Python |\n",
    "| üü° Intermedio | Exportar a ONNX para APIs multi-lenguaje |\n",
    "| üî¥ Avanzado | Usar formatos nativos (LightGBM txt) para m√°xima portabilidad |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b82974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as cargadas\n"
     ]
    }
   ],
   "source": [
    "# Librer√≠as\n",
    "from recursos.utils import load_data\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Cargar utilidades del curso\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "\n",
    "# Crear carpeta para artefactos\n",
    "os.makedirs('../app/models', exist_ok=True)\n",
    "print(\"‚úÖ Librer√≠as cargadas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9111c57",
   "metadata": {},
   "source": [
    "## 1. ¬øPor Qu√© Serializar? ü§î\n",
    "\n",
    "**Serializaci√≥n** = Convertir un objeto en memoria (tu modelo) a un formato que puede guardarse en disco y cargarse despu√©s.\n",
    "\n",
    "### El Ciclo de Vida de un Modelo\n",
    "```\n",
    "[Entrenamiento] ‚Üí [Serializaci√≥n] ‚Üí [Almacenamiento] ‚Üí [Carga] ‚Üí [Inferencia]\n",
    "     Python           ???              Disco/S3         ???        API/App\n",
    "```\n",
    "\n",
    "### ¬øPor Qu√© No Basta con Re-entrenar?\n",
    "| Problema | Consecuencia |\n",
    "|----------|--------------|\n",
    "| Entrenar toma tiempo | Latencia inaceptable en APIs |\n",
    "| Los datos cambian | Resultados no reproducibles |\n",
    "| Dependencia del entorno | \"En mi m√°quina funciona...\" |\n",
    "\n",
    "---\n",
    "## Preparaci√≥n: Entrenar el Modelo Base\n",
    "\n",
    "Primero entrenamos un modelo LightGBM que usaremos para probar todos los formatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e60acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset: 7180 filas, 5 features\n",
      "\n",
      "üöÄ Entrenando LightGBM...\n",
      "‚úÖ AUC en Test: 0.9425\n"
     ]
    }
   ],
   "source": [
    "# Cargar y preparar datos\n",
    "df = load_data('credit_scoring.csv')\n",
    "\n",
    "TARGET_COL = 'target_y'\n",
    "COLS_TO_DROP = [TARGET_COL, 'malo_sf_inicio', 'periodo', 'Unnamed: 0']\n",
    "COLS_SELECT = ['SD_MAX_DIAS_MORA_SSFF_06M',\n",
    "               'MAX_PORC_DEUDA_SOBREGIRO_CUENTA_CORRIENTE_ENTFIN_12M',\n",
    "               'MAX_CNT_ENTIDADES_SSFF_06M',\n",
    "               'NumeroTrabajadores',\n",
    "               'ANTIGUEDAD_RCC_01M']\n",
    "\n",
    "X = df[COLS_SELECT]\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# Solo num√©ricas para simplificar\n",
    "X = X.select_dtypes(include=['int64', 'float64'])\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Split para validaci√≥n\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Guardar nombres de features (metadata cr√≠tico)\n",
    "FEATURE_NAMES = X.columns.tolist()\n",
    "print(f\"üìä Dataset: {X.shape[0]} filas, {len(FEATURE_NAMES)} features\")\n",
    "\n",
    "# Entrenar modelo\n",
    "print(\"\\nüöÄ Entrenando LightGBM...\")\n",
    "model = lgb.LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validar\n",
    "auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "print(f\"‚úÖ AUC en Test: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f6afa",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Nivel 1: Pickle ü•í (Lo B√°sico)\n",
    "\n",
    "**Pickle** es el serializador nativo de Python. Convierte cualquier objeto Python a bytes.\n",
    "\n",
    "### ‚úÖ Ventajas\n",
    "- Viene incluido en Python (no requiere instalar nada)\n",
    "- Funciona con casi cualquier objeto Python\n",
    "\n",
    "### ‚ùå Desventajas\n",
    "- **Solo Python** (no puedes cargar en Java, JS, etc.)\n",
    "- **Fr√°gil:** Si cambias la versi√≥n de scikit-learn, puede fallar\n",
    "- **Inseguro:** Puede ejecutar c√≥digo malicioso al cargar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Archivo: ../app/models/model_pickle.pkl\n",
      "üì¶ Tama√±o: 335.48 KB\n",
      "‚è±Ô∏è Tiempo guardar: 18.83 ms\n",
      "‚è±Ô∏è Tiempo cargar: 34.94 ms\n",
      "‚úÖ AUC verificado: 0.9425\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# M√âTODO 1: PICKLE (B√°sico)\n",
    "# ========================================\n",
    "pickle_path = '../app/models/model_pickle.pkl'\n",
    "\n",
    "# Guardar\n",
    "start = time.time()\n",
    "with open(pickle_path, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "pickle_save_time = time.time() - start\n",
    "\n",
    "# Cargar\n",
    "start = time.time()\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    model_pickle = pickle.load(f)\n",
    "pickle_load_time = time.time() - start\n",
    "\n",
    "# Verificar\n",
    "pred_pickle = model_pickle.predict_proba(X_test)[:, 1]\n",
    "auc_pickle = roc_auc_score(y_test, pred_pickle)\n",
    "\n",
    "pickle_size = os.path.getsize(pickle_path) / 1024  # KB\n",
    "\n",
    "print(f\"üìÅ Archivo: {pickle_path}\")\n",
    "print(f\"üì¶ Tama√±o: {pickle_size:.2f} KB\")\n",
    "print(f\"‚è±Ô∏è Tiempo guardar: {pickle_save_time*1000:.2f} ms\")\n",
    "print(f\"‚è±Ô∏è Tiempo cargar: {pickle_load_time*1000:.2f} ms\")\n",
    "print(f\"‚úÖ AUC verificado: {auc_pickle:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fea36a",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Real-World Warning: Pickle y Seguridad\n",
    "**NUNCA** cargues un archivo `.pkl` de una fuente no confiable.\n",
    "Pickle puede ejecutar c√≥digo arbitrario al deserializar. Un atacante podr√≠a crear un `.pkl` malicioso que borre tu disco o robe credenciales.\n",
    "\n",
    "```python\n",
    "# ‚ùå PELIGRO: No hagas esto con archivos de internet\n",
    "model = pickle.load(open('modelo_de_internet.pkl', 'rb'))  # Podr√≠a ejecutar malware\n",
    "```\n",
    "\n",
    "---\n",
    "## 3. Nivel 2: Joblib üì¶ (El Est√°ndar ML)\n",
    "\n",
    "**Joblib** es una versi√≥n optimizada de Pickle para objetos con arrays grandes (como modelos de ML).\n",
    "\n",
    "### ‚úÖ Ventajas\n",
    "- **M√°s r√°pido** que Pickle para modelos grandes\n",
    "- **Compresi√≥n** integrada (reduce tama√±o en disco)\n",
    "- Est√°ndar en la comunidad ML\n",
    "\n",
    "### ‚ùå Desventajas\n",
    "- Mismos problemas de portabilidad que Pickle\n",
    "- Sigue siendo solo Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b6036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Archivo: ../app/models/model_joblib.joblib\n",
      "üì¶ Tama√±o: 141.72 KB (comprimido)\n",
      "‚è±Ô∏è Tiempo guardar: 22.80 ms\n",
      "‚è±Ô∏è Tiempo cargar: 31.77 ms\n",
      "‚úÖ AUC verificado: 0.9425\n",
      "\n",
      "üìã Metadatos guardados: ['model', 'feature_names', 'target_col', 'auc_test', 'training_date', 'python_version', 'lightgbm_version']\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# M√âTODO 2: JOBLIB (Est√°ndar ML)\n",
    "# ========================================\n",
    "joblib_path = '../app/models/model_joblib.joblib'\n",
    "\n",
    "# Guardar CON metadatos (buena pr√°ctica)\n",
    "artifact = {\n",
    "    'model': model,\n",
    "    'feature_names': FEATURE_NAMES,\n",
    "    'target_col': TARGET_COL,\n",
    "    'auc_test': auc,\n",
    "    'training_date': pd.Timestamp.now().isoformat(),\n",
    "    'python_version': sys.version,\n",
    "    'lightgbm_version': lgb.__version__\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "joblib.dump(artifact, joblib_path, compress=3)  # compress=3 es buen balance\n",
    "joblib_save_time = time.time() - start\n",
    "\n",
    "# Cargar\n",
    "start = time.time()\n",
    "loaded_artifact = joblib.load(joblib_path)\n",
    "joblib_load_time = time.time() - start\n",
    "\n",
    "model_joblib = loaded_artifact['model']\n",
    "\n",
    "# Verificar\n",
    "pred_joblib = model_joblib.predict_proba(X_test)[:, 1]\n",
    "auc_joblib = roc_auc_score(y_test, pred_joblib)\n",
    "\n",
    "joblib_size = os.path.getsize(joblib_path) / 1024\n",
    "\n",
    "print(f\"üìÅ Archivo: {joblib_path}\")\n",
    "print(f\"üì¶ Tama√±o: {joblib_size:.2f} KB (comprimido)\")\n",
    "print(f\"‚è±Ô∏è Tiempo guardar: {joblib_save_time*1000:.2f} ms\")\n",
    "print(f\"‚è±Ô∏è Tiempo cargar: {joblib_load_time*1000:.2f} ms\")\n",
    "print(f\"‚úÖ AUC verificado: {auc_joblib:.4f}\")\n",
    "print(f\"\\nüìã Metadatos guardados: {list(loaded_artifact.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560c364d",
   "metadata": {},
   "source": [
    "> **üí° Pro-Tip: Siempre guarda metadatos**\n",
    "> Incluir `feature_names`, `training_date`, y versiones de librer√≠as te salvar√° cuando en 6 meses alguien pregunte \"¬øCon qu√© datos se entren√≥ esto?\"\n",
    "\n",
    "---\n",
    "## 4. Nivel 3: ONNX üåê (Interoperabilidad)\n",
    "\n",
    "**ONNX (Open Neural Network Exchange)** es un formato abierto para representar modelos de ML.\n",
    "\n",
    "### ‚úÖ Ventajas\n",
    "- **Multi-lenguaje:** Carga en Python, C++, Java, JavaScript, C#\n",
    "- **Optimizado:** Runtime ONNX es muy r√°pido\n",
    "- **Est√°ndar de la industria:** Microsoft, Facebook, Amazon lo usan\n",
    "\n",
    "### ‚ùå Desventajas\n",
    "- Requiere conversi√≥n (no todos los modelos son compatibles)\n",
    "- Necesita instalar `onnxmltools` y `onnxruntime`\n",
    "\n",
    "### üåç Lenguajes Soportados\n",
    "| Lenguaje | Runtime |\n",
    "|----------|---------|\n",
    "| Python | `onnxruntime` |\n",
    "| C++ | ONNX Runtime C++ |\n",
    "| Java | `onnxruntime-java` |\n",
    "| JavaScript | `onnxruntime-web` |\n",
    "| C# | `Microsoft.ML.OnnxRuntime` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b286ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è ONNX no instalado. Ejecuta: pip install onnxmltools onnxruntime\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# M√âTODO 3: ONNX (Multi-lenguaje)\n",
    "# ========================================\n",
    "try:\n",
    "    import onnxmltools\n",
    "    from onnxmltools.convert import convert_lightgbm\n",
    "    from onnxconverter_common import FloatTensorType\n",
    "    import onnxruntime as ort\n",
    "    ONNX_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ONNX_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è ONNX no instalado. Ejecuta: pip install onnxmltools onnxruntime\")\n",
    "\n",
    "if ONNX_AVAILABLE:\n",
    "    onnx_path = '../app/models/model_onnx.onnx'\n",
    "\n",
    "    # Definir el tipo de entrada (n_features como float)\n",
    "    initial_type = [('input', FloatTensorType([None, len(FEATURE_NAMES)]))]\n",
    "\n",
    "    # Convertir modelo\n",
    "    start = time.time()\n",
    "    onnx_model = convert_lightgbm(\n",
    "        model.booster_,  # LightGBM interno\n",
    "        initial_types=initial_type,\n",
    "        target_opset=12\n",
    "    )\n",
    "\n",
    "    # Guardar\n",
    "    with open(onnx_path, 'wb') as f:\n",
    "        f.write(onnx_model.SerializeToString())\n",
    "    onnx_save_time = time.time() - start\n",
    "\n",
    "    # Cargar con ONNX Runtime\n",
    "    start = time.time()\n",
    "    ort_session = ort.InferenceSession(onnx_path)\n",
    "    onnx_load_time = time.time() - start\n",
    "\n",
    "    # Inferencia\n",
    "    input_name = ort_session.get_inputs()[0].name\n",
    "    X_test_np = X_test.values.astype(np.float32)\n",
    "\n",
    "    start = time.time()\n",
    "    onnx_output = ort_session.run(None, {input_name: X_test_np})\n",
    "    onnx_inference_time = time.time() - start\n",
    "\n",
    "    # ONNX devuelve [labels, probabilities]\n",
    "    pred_onnx = onnx_output[1][:, 1]  # Probabilidad clase 1\n",
    "    auc_onnx = roc_auc_score(y_test, pred_onnx)\n",
    "\n",
    "    onnx_size = os.path.getsize(onnx_path) / 1024\n",
    "\n",
    "    print(f\"üìÅ Archivo: {onnx_path}\")\n",
    "    print(f\"üì¶ Tama√±o: {onnx_size:.2f} KB\")\n",
    "    print(f\"‚è±Ô∏è Tiempo conversi√≥n+guardado: {onnx_save_time*1000:.2f} ms\")\n",
    "    print(f\"‚è±Ô∏è Tiempo cargar: {onnx_load_time*1000:.2f} ms\")\n",
    "    print(\n",
    "        f\"‚è±Ô∏è Tiempo inferencia ({len(X_test)} muestras): {onnx_inference_time*1000:.2f} ms\")\n",
    "    print(f\"‚úÖ AUC verificado: {auc_onnx:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d48750",
   "metadata": {},
   "source": [
    "### üìù Ejemplo: Cargar ONNX en JavaScript (Node.js)\n",
    "```javascript\n",
    "// npm install onnxruntime-node\n",
    "const ort = require('onnxruntime-node');\n",
    "\n",
    "async function predict(features) {\n",
    "    const session = await ort.InferenceSession.create('model_onnx.onnx');\n",
    "    const tensor = new ort.Tensor('float32', features, [1, 21]);\n",
    "    const results = await session.run({ input: tensor });\n",
    "    return results.probabilities.data[1];  // P(default)\n",
    "}\n",
    "```\n",
    "\n",
    "### üìù Ejemplo: Cargar ONNX en C++\n",
    "```cpp\n",
    "#include <onnxruntime_cxx_api.h>\n",
    "\n",
    "Ort::Env env(ORT_LOGGING_LEVEL_WARNING, \"CreditModel\");\n",
    "Ort::Session session(env, \"model_onnx.onnx\", Ort::SessionOptions{});\n",
    "// ... preparar input tensor y ejecutar\n",
    "```\n",
    "\n",
    "---\n",
    "## 5. Nivel 4: PMML üè¢ (Legacy Enterprise)\n",
    "\n",
    "**PMML (Predictive Model Markup Language)** es un formato XML antiguo pero a√∫n usado en sistemas bancarios legacy.\n",
    "\n",
    "### ‚úÖ Ventajas\n",
    "- Ampliamente soportado en sistemas empresariales (SAS, SPSS, Java)\n",
    "- Formato de texto (legible y auditable)\n",
    "\n",
    "### ‚ùå Desventajas\n",
    "- **Lento** (XML es verbose)\n",
    "- No soporta modelos muy complejos (deep learning)\n",
    "- Menos preciso que formatos binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83404f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è sklearn2pmml no instalado. Ejecuta: pip install sklearn2pmml\n",
      "   Tambi√©n requiere Java instalado.\n",
      "\n",
      "üìã C√≥digo de referencia para PMML (requiere Java):\n",
      "\n",
      "from sklearn2pmml import sklearn2pmml\n",
      "from sklearn2pmml.pipeline import PMMLPipeline\n",
      "\n",
      "# Crear pipeline compatible con PMML\n",
      "pmml_pipeline = PMMLPipeline([\n",
      "    (\"classifier\", lgb.LGBMClassifier(n_estimators=100))\n",
      "])\n",
      "pmml_pipeline.fit(X_train, y_train)\n",
      "\n",
      "# Exportar\n",
      "sklearn2pmml(pmml_pipeline, \"model.pmml\", with_repr=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# M√âTODO 4: PMML (Enterprise/Legacy)\n",
    "# ========================================\n",
    "try:\n",
    "    from sklearn2pmml import sklearn2pmml\n",
    "    from sklearn2pmml.pipeline import PMMLPipeline\n",
    "    PMML_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PMML_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è sklearn2pmml no instalado. Ejecuta: pip install sklearn2pmml\")\n",
    "    print(\"   Tambi√©n requiere Java instalado.\")\n",
    "\n",
    "# Nota: PMML requiere Java y configuraci√≥n especial.\n",
    "# Mostramos el c√≥digo de referencia:\n",
    "print(\"\"\"\n",
    "üìã C√≥digo de referencia para PMML (requiere Java):\n",
    "\n",
    "from sklearn2pmml import sklearn2pmml\n",
    "from sklearn2pmml.pipeline import PMMLPipeline\n",
    "\n",
    "# Crear pipeline compatible con PMML\n",
    "pmml_pipeline = PMMLPipeline([\n",
    "    (\"classifier\", lgb.LGBMClassifier(n_estimators=100))\n",
    "])\n",
    "pmml_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Exportar\n",
    "sklearn2pmml(pmml_pipeline, \"model.pmml\", with_repr=True)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8786f6",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Nivel 5: Formatos Nativos üéØ (M√°xima Portabilidad)\n",
    "\n",
    "Cada librer√≠a tiene su **formato nativo** optimizado. Para LightGBM, es un archivo de texto que contiene la estructura de todos los √°rboles.\n",
    "\n",
    "### ‚úÖ Ventajas\n",
    "- **M√°xima portabilidad:** Carga en C++, Java, Go, Rust (cualquier binding de LightGBM)\n",
    "- **Sin dependencias de Python:** Perfecto para embebidos o microservicios\n",
    "- **Texto plano:** Auditable y versionable en Git\n",
    "\n",
    "### ‚ùå Desventajas\n",
    "- Espec√≠fico de cada librer√≠a (LightGBM ‚â† XGBoost ‚â† CatBoost)\n",
    "- No incluye preprocesamiento (solo el modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d620be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Archivo: ../app/models/model_lgb.txt\n",
      "üì¶ Tama√±o: 333.72 KB\n",
      "‚è±Ô∏è Tiempo guardar: 27.37 ms\n",
      "‚è±Ô∏è Tiempo cargar: 79.38 ms\n",
      "‚úÖ AUC verificado: 0.9425\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# M√âTODO 5A: LightGBM Nativo (Texto)\n",
    "# ========================================\n",
    "lgb_txt_path = '../app/models/model_lgb.txt'\n",
    "\n",
    "# Guardar en formato texto nativo\n",
    "start = time.time()\n",
    "model.booster_.save_model(lgb_txt_path)\n",
    "lgb_txt_save_time = time.time() - start\n",
    "\n",
    "# Cargar\n",
    "start = time.time()\n",
    "model_lgb_txt = lgb.Booster(model_file=lgb_txt_path)\n",
    "lgb_txt_load_time = time.time() - start\n",
    "\n",
    "# Verificar\n",
    "pred_lgb_txt = model_lgb_txt.predict(X_test)\n",
    "auc_lgb_txt = roc_auc_score(y_test, pred_lgb_txt)\n",
    "\n",
    "lgb_txt_size = os.path.getsize(lgb_txt_path) / 1024\n",
    "\n",
    "print(f\"üìÅ Archivo: {lgb_txt_path}\")\n",
    "print(f\"üì¶ Tama√±o: {lgb_txt_size:.2f} KB\")\n",
    "print(f\"‚è±Ô∏è Tiempo guardar: {lgb_txt_save_time*1000:.2f} ms\")\n",
    "print(f\"‚è±Ô∏è Tiempo cargar: {lgb_txt_load_time*1000:.2f} ms\")\n",
    "print(f\"‚úÖ AUC verificado: {auc_lgb_txt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d9eb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Primeras 30 l√≠neas del modelo LightGBM (texto):\n",
      "\n",
      "tree\n",
      "version=v4\n",
      "num_class=1\n",
      "num_tree_per_iteration=1\n",
      "label_index=0\n",
      "max_feature_idx=4\n",
      "objective=binary sigmoid:1\n",
      "feature_names=SD_MAX_DIAS_MORA_SSFF_06M MAX_PORC_DEUDA_SOBREGIRO_CUENTA_CORRIENTE_ENTFIN_12M MAX_CNT_ENTIDADES_SSFF_06M NumeroTrabajadores ANTIGUEDAD_RCC_01M\n",
      "feature_infos=[0:192.61092042422399] [1.14e-08:1] [1:10] [0:1433] [0:57]\n",
      "tree_sizes=3324 3335 3349 3348 3368 3359 3384 3360 3364 3356 3357 3363 3365 3372 3370 3383 3362 3371 3394 3366 3373 3388 3391 3366 3393 3381 3385 3387 3387 3394 3379 3376 3368 3367 3393 3380 3361 3380 3384 3377 3384 3391 3384 3388 3365 3366 3396 3395 3362 3401 3376 3357 3401 3364 3397 3392 3376 3397 3385 3426 3400 3366 3388 3399 3375 3387 3431 3385 3393 3363 3368 3362 3389 3389 3423 3373 3391 3396 3417 3377 3395 3348 3371 3381 3403 3379 3385 3428 3358 3374 3367 3387 3395 3389 3378 3390 3435 3378 3396 3405\n",
      "\n",
      "Tree=0\n",
      "num_leaves=31\n",
      "num_cat=0\n",
      "split_feature=0 2 0 1 0 3 2 1 1 2 1 3 0 0 4 3 0 1 0 4 2 0 1 3 1 1 1 1 1 1\n",
      "split_gain=1352.49 157.703 138.128 90.5521 52.8857 33.9457 40.8046 31.5723 53.0414 29.723 25.908 21.3201 20.1575 21.8828 19.8093 18.5584 18.3969 15.3956 15.0445 14.6884 14.2584 26.0534 13.7629 13.4133 12.6081 12.3374 12.1139 22.1045 11.7671 11.6826\n",
      "threshold=2.4663835735375357 5.5000000000000009 0.53206016849974402 0.033671453450000007 8.5761291677760081 17.500000000000004 4.5000000000000009 0.0010117603500000001 0.0095880836500000007 3.5000000000000004 0.018466975900000005 16.500000000000004 22.804898970681155 14.311951113005152 54.500000000000007 3.5000000000000004 2.8077258634530304 0.014560098250000002 10.001664306688108 45.500000000000007 2.5000000000000004 6.1400109728032506 0.025184340700000005 5.5000000000000009 0.0023321866500000004 0.27632158020000003 0.015283770650000002 0.00081266195000000011 0.00075551795000000004 0.0021663782000000006\n",
      "decision_type=2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      "left_child=2 3 22 4 11 6 15 28 -9 25 17 20 13 19 -12 18 -3 29 -5 -7 -2 -22 -1 -17 -18 -4 27 -13 -6 -11\n",
      "right_child=1 16 9 5 7 12 -8 8 -10 10 14 26 -14 -15 -16 23 24 -19 -20 -21 21 -23 -24 -25 -26 -27 -28 -29 -30 -31\n",
      "leaf_value=-1.2384239838898643 -1.1567347122049876 -1.0386904170142501 -1.2152849920410747 -0.75974100103246933 -1.0469401397488431 -0.95769160869562575 -0.79229172819591076 -0.81830496681869946 -1.051019672969246 -1.1252053664711814 -0.9847933350842244 -1.1989707444291962 -1.1736633243110468 -0.81648359946171145 -1.2320285619585289 -1.143158844704349 -0.9124502076789347 -1.1936388383760781 -0.93327878122856833 -1.1167216290452109 -1.0808450696002621 -0.88717542000480909 -1.1963728805762035 -0.96928331094617093 -0.81975258538277951 -1.1115451112937711 -1.233619579914486 -0.97436739088062052 -1.2344874078904629 -1.0194162004263769\n",
      "leaf_weight=450.32213258743286 13.679736375808714 4.9912551641464225 38.820873498916626 7.2095907926559475 18.855852842330936 12.940291166305547 22.922801494598389 19.965020656585693 19.22557544708252 36.602537870407104 26.250304937362674 11.64626204967499 7.0247294902801505 6.1004229784011832 3.6972260475158683 5.1761164665222159 19.040714144706726 22.922801494598389 16.267794609069824 10.537094235420225 31.981005311012268 8.8733425140380842 94.09440290927887 31.056698799133301 63.962010622024536 16.267794609069824 15.713210701942442 7.0247294902801505 4.0669486522674552 14.604042887687681\n",
      "leaf_count=2436 74 27 210 39 102 70 124 108 104 198 142 63 38 33 20 28 103 124 88 57 173 48 509 168 346 88 85 38 22 79\n",
      "internal_value=-1.12666 -0.968506 -1.2072 -1.00636 -1.05779 -0.941218 -0.905706 -0.986993 -0.932467 -1.12525 -1.09381 -1.10725 -1.02139 -0.985222 -1.01532 -0.949246 -0.85223 -1.12553 -0.879988 -1.02907 -1.06837 -1.03878 -1.23116 -0.994123 -0.841017 -1.18465 -1.16892 -1.11447 -1.08021 -1.09503\n",
      "internal_weight=1061.84 358.261 703.582 270.267 151.032 119.236 82.633 62.1134 39.1906 159.166 104.077 88.9183 36.6025 29.5778 29.9475 59.7102 87.994 74.1294 23.4774 23.4774 54.5341 40.8543 544.417 36.2328 83.0027 55.0887 34.3842 18.671 22.9228 51.2066\n",
      "internal_count=5744 1938 3806 1462 817 645 447 336 212 861 563 481 198 160 162 323 476 401 127 127 295 221 2945 196 449 298 186 101 124 277\n",
      "is_linear=0\n",
      "shrinkage=1\n",
      "\n",
      "\n",
      "... (contin√∫a)\n"
     ]
    }
   ],
   "source": [
    "# Veamos c√≥mo se ve el archivo de texto\n",
    "print(\"üìÑ Primeras 30 l√≠neas del modelo LightGBM (texto):\\n\")\n",
    "with open(lgb_txt_path, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i < 30:\n",
    "            print(line.rstrip())\n",
    "        else:\n",
    "            print(\"... (contin√∫a)\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d82a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Metadatos guardados: ../app/models/model_metadata.json\n",
      "\n",
      "üìã Contenido:\n",
      "{\n",
      "  \"model_type\": \"LightGBMClassifier\",\n",
      "  \"model_file\": \"model_lgb.txt\",\n",
      "  \"feature_names\": [\n",
      "    \"SD_MAX_DIAS_MORA_SSFF_06M\",\n",
      "    \"MAX_PORC_DEUDA_SOBREGIRO_CUENTA_CORRIENTE_ENTFIN_12M\",\n",
      "    \"MAX_CNT_ENTIDADES_SSFF_06M\",\n",
      "    \"NumeroTrabajadores\",\n",
      "    \"ANTIGUEDAD_RCC_01M\"\n",
      "  ],\n",
      "  \"n_features\": 5,\n",
      "  \"target_col\": \"target_y\",\n",
      "  \"metrics\": {\n",
      "    \"auc_test\": 0.9425,\n",
      "    \"n_train_samples\": 5744,\n",
      "    \"n_test_samples\": 1436\n",
      "  },\n",
      "  \"training_info\": {\n",
      "    \"date\": \"2025-12-06T02:54:35.175460\",\n",
      "    \"lightgbm_version\": \"4.6.0\",\n",
      "    \"n_estimators\": 100\n",
      "  },\n",
      "  \"feature_importance\": {\n",
      "    \"SD_MAX_DIAS_MORA_SSFF_06M\": 676,\n",
      "    \"MAX_PORC_DEUDA_SOBREGIRO_CUENTA_CORRIENTE_ENTFIN_12M\": 715,\n",
      "    \"MAX_CNT_ENTIDADES_SSFF_06M\": 263,\n",
      "    \"NumeroTrabajadores\": 839,\n",
      "    \"ANTIGUEDAD_RCC_01M\": 507\n",
      "  }\n",
      "}...\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# M√âTODO 5B: JSON + Metadatos (Para APIs)\n",
    "# ========================================\n",
    "json_path = '../app/models/model_metadata.json'\n",
    "\n",
    "# Guardar metadatos en JSON (legible por cualquier lenguaje)\n",
    "metadata = {\n",
    "    'model_type': 'LightGBMClassifier',\n",
    "    'model_file': 'model_lgb.txt',\n",
    "    'feature_names': FEATURE_NAMES,\n",
    "    'n_features': len(FEATURE_NAMES),\n",
    "    'target_col': TARGET_COL,\n",
    "    'metrics': {\n",
    "        'auc_test': round(auc, 4),\n",
    "        'n_train_samples': len(X_train),\n",
    "        'n_test_samples': len(X_test)\n",
    "    },\n",
    "    'training_info': {\n",
    "        'date': pd.Timestamp.now().isoformat(),\n",
    "        'lightgbm_version': lgb.__version__,\n",
    "        'n_estimators': model.n_estimators\n",
    "    },\n",
    "    'feature_importance': dict(zip(\n",
    "        FEATURE_NAMES,\n",
    "        model.feature_importances_.tolist()\n",
    "    ))\n",
    "}\n",
    "\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"üìÅ Metadatos guardados: {json_path}\")\n",
    "print(f\"\\nüìã Contenido:\")\n",
    "print(json.dumps(metadata, indent=2)[:1000] + \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d0e46",
   "metadata": {},
   "source": [
    "### üìù Ejemplo: Cargar en C++ (LightGBM Nativo)\n",
    "```cpp\n",
    "#include <LightGBM/c_api.h>\n",
    "\n",
    "BoosterHandle booster;\n",
    "LGBM_BoosterCreateFromModelfile(\"model_lgb.txt\", &num_iterations, &booster);\n",
    "\n",
    "// Predecir\n",
    "double prediction;\n",
    "LGBM_BoosterPredictForMat(booster, data, ...);\n",
    "```\n",
    "\n",
    "### üìù Ejemplo: Cargar en Java\n",
    "```java\n",
    "import ml.dmlc.lightgbm4j.LightGBM;\n",
    "\n",
    "Booster booster = Booster.loadModel(\"model_lgb.txt\");\n",
    "double[] predictions = booster.predict(features);\n",
    "```\n",
    "\n",
    "---\n",
    "## 7. Comparativa Final üìä\n",
    "\n",
    "Creemos una tabla resumen con todos los m√©todos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb04531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä COMPARATIVA DE FORMATOS DE SERIALIZACI√ìN\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Formato",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tama√±o (KB)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "T. Guardar (ms)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "T. Cargar (ms)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Multi-Lenguaje",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Incluye Metadata",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Uso Recomendado",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d4a17253-dfff-4f06-95ca-799f9102ae4d",
       "rows": [
        [
         "0",
         "Pickle",
         "335.48",
         "18.83",
         "34.94",
         "‚ùå Solo Python",
         "‚ùå",
         "Prototipos r√°pidos"
        ],
        [
         "1",
         "Joblib",
         "141.72",
         "22.8",
         "31.77",
         "‚ùå Solo Python",
         "‚úÖ (manual)",
         "Producci√≥n Python"
        ],
        [
         "2",
         "ONNX",
         "N/A",
         "N/A",
         "N/A",
         "‚úÖ S√≠",
         "‚ùå",
         "APIs multi-lenguaje"
        ],
        [
         "3",
         "LightGBM Nativo",
         "333.72",
         "27.37",
         "79.38",
         "‚úÖ S√≠",
         "‚ùå",
         "Microservicios C++/Java"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Formato</th>\n",
       "      <th>Tama√±o (KB)</th>\n",
       "      <th>T. Guardar (ms)</th>\n",
       "      <th>T. Cargar (ms)</th>\n",
       "      <th>Multi-Lenguaje</th>\n",
       "      <th>Incluye Metadata</th>\n",
       "      <th>Uso Recomendado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pickle</td>\n",
       "      <td>335.48</td>\n",
       "      <td>18.83</td>\n",
       "      <td>34.94</td>\n",
       "      <td>‚ùå Solo Python</td>\n",
       "      <td>‚ùå</td>\n",
       "      <td>Prototipos r√°pidos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joblib</td>\n",
       "      <td>141.72</td>\n",
       "      <td>22.8</td>\n",
       "      <td>31.77</td>\n",
       "      <td>‚ùå Solo Python</td>\n",
       "      <td>‚úÖ (manual)</td>\n",
       "      <td>Producci√≥n Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ONNX</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>‚úÖ S√≠</td>\n",
       "      <td>‚ùå</td>\n",
       "      <td>APIs multi-lenguaje</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM Nativo</td>\n",
       "      <td>333.72</td>\n",
       "      <td>27.37</td>\n",
       "      <td>79.38</td>\n",
       "      <td>‚úÖ S√≠</td>\n",
       "      <td>‚ùå</td>\n",
       "      <td>Microservicios C++/Java</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Formato Tama√±o (KB) T. Guardar (ms) T. Cargar (ms) Multi-Lenguaje  \\\n",
       "0           Pickle      335.48           18.83          34.94  ‚ùå Solo Python   \n",
       "1           Joblib      141.72            22.8          31.77  ‚ùå Solo Python   \n",
       "2             ONNX         N/A             N/A            N/A           ‚úÖ S√≠   \n",
       "3  LightGBM Nativo      333.72           27.37          79.38           ‚úÖ S√≠   \n",
       "\n",
       "  Incluye Metadata          Uso Recomendado  \n",
       "0                ‚ùå       Prototipos r√°pidos  \n",
       "1       ‚úÖ (manual)        Producci√≥n Python  \n",
       "2                ‚ùå      APIs multi-lenguaje  \n",
       "3                ‚ùå  Microservicios C++/Java  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================================\n",
    "# COMPARATIVA FINAL\n",
    "# ========================================\n",
    "\n",
    "comparison_data = {\n",
    "    'Formato': ['Pickle', 'Joblib', 'ONNX', 'LightGBM Nativo'],\n",
    "    'Tama√±o (KB)': [\n",
    "        round(pickle_size, 2),\n",
    "        round(joblib_size, 2),\n",
    "        round(onnx_size, 2) if ONNX_AVAILABLE else 'N/A',\n",
    "        round(lgb_txt_size, 2)\n",
    "    ],\n",
    "    'T. Guardar (ms)': [\n",
    "        round(pickle_save_time*1000, 2),\n",
    "        round(joblib_save_time*1000, 2),\n",
    "        round(onnx_save_time*1000, 2) if ONNX_AVAILABLE else 'N/A',\n",
    "        round(lgb_txt_save_time*1000, 2)\n",
    "    ],\n",
    "    'T. Cargar (ms)': [\n",
    "        round(pickle_load_time*1000, 2),\n",
    "        round(joblib_load_time*1000, 2),\n",
    "        round(onnx_load_time*1000, 2) if ONNX_AVAILABLE else 'N/A',\n",
    "        round(lgb_txt_load_time*1000, 2)\n",
    "    ],\n",
    "    'Multi-Lenguaje': ['‚ùå Solo Python', '‚ùå Solo Python', '‚úÖ S√≠', '‚úÖ S√≠'],\n",
    "    'Incluye Metadata': ['‚ùå', '‚úÖ (manual)', '‚ùå', '‚ùå'],\n",
    "    'Uso Recomendado': [\n",
    "        'Prototipos r√°pidos',\n",
    "        'Producci√≥n Python',\n",
    "        'APIs multi-lenguaje',\n",
    "        'Microservicios C++/Java'\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"üìä COMPARATIVA DE FORMATOS DE SERIALIZACI√ìN\")\n",
    "print(\"=\" * 80)\n",
    "display(comparison_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6be2ccf",
   "metadata": {},
   "source": [
    "### üéØ √Årbol de Decisi√≥n: ¬øQu√© Formato Usar?\n",
    "\n",
    "```\n",
    "¬øTu API es Python?\n",
    "    ‚îÇ\n",
    "    ‚îú‚îÄ‚îÄ S√ç ‚Üí ¬øModelo grande (>100MB)?\n",
    "    ‚îÇ           ‚îÇ\n",
    "    ‚îÇ           ‚îú‚îÄ‚îÄ S√ç ‚Üí Joblib (comprimido)\n",
    "    ‚îÇ           ‚îî‚îÄ‚îÄ NO ‚Üí Joblib (est√°ndar)\n",
    "    ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ NO ‚Üí ¬øNecesitas m√°xima velocidad?\n",
    "                ‚îÇ\n",
    "                ‚îú‚îÄ‚îÄ S√ç ‚Üí Formato Nativo (LightGBM txt, XGBoost json)\n",
    "                ‚îî‚îÄ‚îÄ NO ‚Üí ONNX (m√°s flexible)\n",
    "```\n",
    "\n",
    "### ‚ö†Ô∏è Real-World Warning: Versionamiento de Modelos\n",
    "En producci√≥n, **SIEMPRE** incluye metadatos con cada modelo:\n",
    "- Versi√≥n de librer√≠as usadas\n",
    "- Fecha de entrenamiento\n",
    "- Hash de los datos de entrenamiento\n",
    "- M√©tricas de validaci√≥n\n",
    "\n",
    "Sin esto, en 6 meses no sabr√°s qu√© modelo es cu√°l.\n",
    "\n",
    "---\n",
    "## 8. üß† Micro-Desaf√≠o: Exportar para tu Stack\n",
    "\n",
    "Elige el formato correcto para cada escenario:\n",
    "\n",
    "1. **Escenario A:** Tu equipo de Backend usa FastAPI (Python) y necesita servir predicciones con latencia < 50ms.\n",
    "\n",
    "2. **Escenario B:** El equipo m√≥vil quiere ejecutar el modelo directamente en la app iOS (Swift).\n",
    "\n",
    "3. **Escenario C:** El banco tiene un sistema legacy en COBOL que necesita consumir las predicciones.\n",
    "\n",
    "> **üí° Pista para B:** Busca \"Core ML\" de Apple. ONNX puede convertirse a Core ML.\n",
    "\n",
    "---\n",
    "## üèÜ Resumen de Logros\n",
    "\n",
    "¬°Felicidades! Ahora sabes:\n",
    "1. **Pickle/Joblib:** Para entornos Python puros\n",
    "2. **ONNX:** El formato universal para multi-lenguaje\n",
    "3. **Formatos Nativos:** Para m√°ximo rendimiento en C++/Java\n",
    "4. **La importancia de metadatos:** Sin ellos, el modelo es una caja negra\n",
    "\n",
    "### üìÅ Archivos Generados\n",
    "```\n",
    "app/models/\n",
    "‚îú‚îÄ‚îÄ model_pickle.pkl      # Python b√°sico\n",
    "‚îú‚îÄ‚îÄ model_joblib.joblib   # Python + metadatos\n",
    "‚îú‚îÄ‚îÄ model_onnx.onnx       # Multi-lenguaje\n",
    "‚îú‚îÄ‚îÄ model_lgb.txt         # LightGBM nativo\n",
    "‚îî‚îÄ‚îÄ model_metadata.json   # Documentaci√≥n\n",
    "```\n",
    "\n",
    "üëâ **Siguiente Paso:** Ahora que tienes el modelo serializado, vamos a crear una **aplicaci√≥n web con Streamlit** que lo consuma en tiempo real."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
