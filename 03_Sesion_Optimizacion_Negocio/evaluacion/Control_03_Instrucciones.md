# ğŸ“ Control NÂ° 3: OptimizaciÃ³n y CalibraciÃ³n de Modelos

**Curso:** Machine Learning Supervisado - PECD UNI  
**Docente:** Jordan King Rodriguez Mallqui  
**SesiÃ³n:** 03 - OptimizaciÃ³n y CalibraciÃ³n  
**Fecha de entrega:** _07/12/2025_  
**Modalidad:** Individual o en parejas

---

## ğŸ¯ Objetivo

Aplicar tÃ©cnicas de **optimizaciÃ³n de hiperparÃ¡metros** (Optuna, GridSearchCV, RandomizedSearchCV), **calibraciÃ³n de probabilidades**, **selecciÃ³n de umbrales** y **anÃ¡lisis de curvas de rentabilidad** para maximizar el valor de negocio de un modelo de clasificaciÃ³n.

---

## ğŸ“‹ Instrucciones Generales

### 1. SelecciÃ³n del Dataset

Puedes usar el **mismo dataset de los controles anteriores** o elegir uno nuevo. Para este control, se recomienda usar un dataset de **clasificaciÃ³n binaria** donde el contexto de negocio permita definir costos/beneficios.

#### ğŸ”¹ OpciÃ³n A: Datasets Sugeridos (ClasificaciÃ³n con Contexto de Negocio)

| Dataset | DescripciÃ³n | Contexto de Negocio | Enlace |
|---------|-------------|---------------------|--------|
| **Telco Churn** | PredicciÃ³n de fuga de clientes | Costo de retenciÃ³n vs valor del cliente | [Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn) |
| **Credit Risk** | PredicciÃ³n de default crediticio | PÃ©rdida por default vs beneficio por interÃ©s | [Kaggle](https://www.kaggle.com/datasets/laotse/credit-risk-dataset) |
| **Bank Marketing** | SuscripciÃ³n a depÃ³sito | Costo de llamada vs valor del depÃ³sito | [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/bank+marketing) |
| **Employee Attrition** | PredicciÃ³n de rotaciÃ³n laboral | Costo de reclutamiento vs retenciÃ³n | [Kaggle](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset) |
| **Insurance Cross-Sell** | PredicciÃ³n de venta cruzada | Costo de campaÃ±a vs prima de seguro | [Kaggle](https://www.kaggle.com/datasets/anmolkumar/health-insurance-cross-sell-prediction) |

#### ğŸ”¹ OpciÃ³n B: Dataset Propio

Requisitos:
- Problema de **clasificaciÃ³n binaria**
- Disponible en **repositorio pÃºblico**
- Al menos **1,000 registros** (para que Optuna tenga suficientes datos)
- Definir claramente un **contexto de negocio** con costos/beneficios

---

## ğŸ“¦ Entregables

### Notebook Jupyter con las siguientes secciones:

#### **1. IntroducciÃ³n y Contexto de Negocio** (10 pts)
- DescripciÃ³n del problema
- DefiniciÃ³n de la **matriz de costos/beneficios**:
  - Beneficio de un True Positive (TP)
  - Costo de un False Positive (FP)
  - Costo de un False Negative (FN)
  - Beneficio/Costo de un True Negative (TN)
- Ejemplo: En un modelo de churn, Â¿cuÃ¡nto cuesta perder un cliente vs cuÃ¡nto cuesta una campaÃ±a de retenciÃ³n fallida?

#### **2. Preprocesamiento y Modelo Base** (10 pts)
- Pipeline de preprocesamiento (reutilizar de controles anteriores)
- Entrenar un modelo base (ej: LightGBM con hiperparÃ¡metros por defecto)
- MÃ©tricas iniciales de referencia

#### **3. OptimizaciÃ³n con Optuna** (30 pts)

Implementar un estudio de Optuna que:
- Defina un **espacio de bÃºsqueda** de al menos **5 hiperparÃ¡metros**
- Use **cross-validation** dentro de la funciÃ³n objetivo
- Ejecute al menos **50 trials**
- Incluya **pruning** para eficiencia

```python
# Ejemplo de estructura esperada
import optuna

def objective(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 500),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
        # ... mÃ¡s hiperparÃ¡metros
    }
    
    model = LGBMClassifier(**params, random_state=42)
    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')
    return scores.mean()

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)
```

Documentar:
- Visualizaciones de Optuna (`plot_optimization_history`, `plot_param_importances`)
- Mejores hiperparÃ¡metros encontrados
- ComparaciÃ³n con modelo base

#### **4. CalibraciÃ³n de Probabilidades** (15 pts)

Aplicar al menos **2 mÃ©todos de calibraciÃ³n**:
- `CalibratedClassifierCV` con mÃ©todo `'isotonic'`
- `CalibratedClassifierCV` con mÃ©todo `'sigmoid'` (Platt Scaling)

Evaluar la calibraciÃ³n con:
- **Diagrama de CalibraciÃ³n** (`CalibrationDisplay`)
- **Brier Score** antes y despuÃ©s de calibrar
- AnÃ¡lisis: Â¿MejorÃ³ la calibraciÃ³n? Â¿CÃ³mo afectÃ³ otras mÃ©tricas?

#### **5. SelecciÃ³n de Umbral Ã“ptimo** (15 pts)

Implementar selecciÃ³n de umbral basada en:
- **MaximizaciÃ³n de F1-Score** (umbral estÃ¡ndar)
- **MaximizaciÃ³n del beneficio esperado** (usando la matriz de costos definida)

```python
# Ejemplo: Encontrar umbral que maximiza beneficio
def calcular_beneficio(y_true, y_pred, umbral, beneficios):
    y_pred_class = (y_pred >= umbral).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()
    
    beneficio_total = (
        tp * beneficios['TP'] +
        tn * beneficios['TN'] -
        fp * beneficios['FP'] -
        fn * beneficios['FN']
    )
    return beneficio_total

# Buscar umbral Ã³ptimo
umbrales = np.arange(0.1, 0.9, 0.01)
beneficios_por_umbral = [calcular_beneficio(y_test, probs, u, matriz_costos) for u in umbrales]
umbral_optimo = umbrales[np.argmax(beneficios_por_umbral)]
```

Incluir:
- GrÃ¡fico de beneficio vs umbral
- ComparaciÃ³n de umbral 0.5 vs umbral Ã³ptimo
- Impacto en mÃ©tricas (Precision, Recall, F1)

#### **6. Curva de Rentabilidad (Profit Curve)** (15 pts)

Implementar y analizar:
- **Curva Lift**
- **Curva de Ganancia Acumulada**
- **Curva de Beneficio**

```python
# Ejemplo: Curva de beneficio acumulado
def profit_curve(y_true, y_proba, costo_accion, beneficio_acierto):
    # Ordenar por probabilidad descendente
    sorted_indices = np.argsort(y_proba)[::-1]
    y_sorted = y_true.iloc[sorted_indices].values
    
    # Calcular beneficio acumulado
    n = len(y_true)
    beneficios = []
    for i in range(1, n+1):
        tp = y_sorted[:i].sum()
        fp = i - tp
        beneficio = tp * beneficio_acierto - i * costo_accion
        beneficios.append(beneficio)
    
    return np.arange(1, n+1) / n * 100, beneficios
```

AnÃ¡lisis requerido:
- Â¿A quÃ© porcentaje de la poblaciÃ³n deberÃ­amos aplicar la acciÃ³n?
- Â¿CuÃ¡l es el beneficio mÃ¡ximo esperado?
- ComparaciÃ³n con estrategia aleatoria

#### **7. Conclusiones y Recomendaciones** (5 pts)
- Resumen de mejoras obtenidas en cada etapa
- RecomendaciÃ³n final: Â¿QuÃ© modelo, umbral y estrategia usar en producciÃ³n?
- Limitaciones y prÃ³ximos pasos

---

## âš ï¸ Criterios de EvaluaciÃ³n

| Criterio | Puntos | DescripciÃ³n |
|----------|--------|-------------|
| **Reproducibilidad** | 10 | Notebook ejecutable de principio a fin |
| **Contexto de negocio** | 10 | Matriz de costos bien definida y justificada |
| **Optuna implementado** | 30 | Estudio completo con visualizaciones |
| **CalibraciÃ³n correcta** | 15 | Dos mÃ©todos comparados con Brier Score |
| **SelecciÃ³n de umbral** | 15 | Umbral basado en negocio, no solo F1 |
| **Curvas de rentabilidad** | 15 | Profit curve con anÃ¡lisis de negocio |
| **Conclusiones** | 5 | RecomendaciÃ³n clara y fundamentada |
| **TOTAL** | **100** | |

---

## ğŸš« Errores que Penalizan

- âŒ Optuna con menos de 30 trials (-10 pts)
- âŒ No usar cross-validation en Optuna (-15 pts)
- âŒ Calibrar en el mismo set de entrenamiento (data leakage) (-10 pts)
- âŒ No definir matriz de costos de negocio (-10 pts)
- âŒ Notebook que no ejecuta de principio a fin (-20 pts)
- âŒ Solo usar umbral 0.5 sin anÃ¡lisis (-10 pts)

---

## ğŸ“¤ Formato de Entrega

1. **Archivo:** `Control03_Apellido_Nombre.ipynb`
2. **Plataforma:** [Canvas](https://canvas.instructure.com/courses/12906015)

### Estructura sugerida del notebook:

```
1. TÃ­tulo y datos del alumno
2. IntroducciÃ³n y Contexto de Negocio
3. Carga de Datos y Preprocesamiento
4. Modelo Base (Benchmark)
5. OptimizaciÃ³n con Optuna
6. CalibraciÃ³n de Probabilidades
7. SelecciÃ³n de Umbral Ã“ptimo
8. Curvas de Rentabilidad
9. Conclusiones y Recomendaciones
10. Referencias
```

---

## ğŸ’¡ Tips para un Buen Trabajo

1. **Define el negocio primero:** Sin matriz de costos clara, la optimizaciÃ³n no tiene sentido
2. **Optuna con paciencia:** 50+ trials para resultados estables
3. **CalibraciÃ³n separada:** Usar un conjunto de calibraciÃ³n diferente al de entrenamiento
4. **Visualiza todo:** Los stakeholders entienden mejor con grÃ¡ficos
5. **El umbral importa:** Un modelo excelente con umbral incorrecto es inÃºtil

### CÃ³digo de Referencia: VisualizaciÃ³n de Optuna

```python
from optuna.visualization import (
    plot_optimization_history,
    plot_param_importances,
    plot_contour
)

# Historial de optimizaciÃ³n
fig1 = plot_optimization_history(study)
fig1.show()

# Importancia de hiperparÃ¡metros
fig2 = plot_param_importances(study)
fig2.show()
```

---

## ğŸ“š Recursos de Apoyo

### ğŸ“‚ Repositorio del Curso
Todo el material estÃ¡ disponible en:

ğŸ”— **[https://github.com/JordanKingPeru/ml-supervisado-uni](https://github.com/JordanKingPeru/ml-supervisado-uni)**

### ğŸ““ Notebooks de la SesiÃ³n 3
- `01_Hyperparameter_Optimization.ipynb` - Optuna y bÃºsqueda de hiperparÃ¡metros
- `02_Probability_Calibration.ipynb` - CalibraciÃ³n de probabilidades
- `03_Threshold_Selection.ipynb` - SelecciÃ³n de umbrales
- `04_Profit_Curves.ipynb` - Curvas de rentabilidad

### ğŸ”— DocumentaciÃ³n Oficial
- [Optuna Documentation](https://optuna.readthedocs.io/)
- [CalibratedClassifierCV - Scikit-Learn](https://scikit-learn.org/stable/modules/calibration.html)
- [Probability Calibration - Scikit-Learn Guide](https://scikit-learn.org/stable/modules/calibration.html)
- [Classification Metrics - Scikit-Learn](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)

### ğŸ“– Lecturas Recomendadas
- *"Profit-Driven Business Analytics"* - Verbeke et al.
- *"Calibrating Probabilities"* - Platt (1999)

---

## â“ Preguntas Frecuentes

**P: Â¿Puedo usar GridSearchCV en vez de Optuna?**  
R: SÃ­, pero Optuna tiene puntos extra (+5 pts). Si usas GridSearchCV, asegÃºrate de que sea suficientemente exhaustivo.

**P: Â¿CÃ³mo defino los costos si no tengo informaciÃ³n del negocio?**  
R: Puedes asumir valores razonables y documentar tus supuestos. Ejemplo: "Asumimos que perder un cliente cuesta 5x mÃ¡s que una campaÃ±a de retenciÃ³n fallida".

**P: Â¿CuÃ¡ntos trials son suficientes en Optuna?**  
R: MÃ­nimo 50 para este control. En producciÃ³n real, 100-500 trials son comunes.

**P: Â¿Es obligatorio calibrar si el modelo ya da buenas probabilidades?**  
R: SÃ­, debes mostrar el proceso y comparar. A veces la calibraciÃ³n empeora modelos ya bien calibrados.

**P: Â¿Puedo usar otros optimizadores como Hyperopt o Ray Tune?**  
R: SÃ­, se aceptan como alternativas vÃ¡lidas a Optuna.

---

## ğŸ† Bonus Points (+10 pts mÃ¡ximo)

- **+5 pts:** Implementar Early Stopping con Optuna (pruning)
- **+3 pts:** Comparar `'isotonic'` vs `'sigmoid'` en detalle
- **+2 pts:** Incluir anÃ¡lisis de sensibilidad de la matriz de costos

---

Â¡Ã‰xitos! ğŸš€âš™ï¸

