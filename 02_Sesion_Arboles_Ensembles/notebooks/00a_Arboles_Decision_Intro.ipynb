{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47735b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ Imports y ConfiguraciÃ³n\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.datasets import make_moons, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ConfiguraciÃ³n Visual\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617e4d43",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. El Problema de la Linealidad\n",
    "\n",
    "La RegresiÃ³n LogÃ­stica dibuja una **lÃ­nea recta** para separar clases. Pero, Â¿quÃ© pasa cuando los datos tienen forma de \"lunas\"? ğŸŒ™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c99e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos en forma de lunas\n",
    "X_moons, y_moons = make_moons(\n",
    "    n_samples=300, noise=0.25, random_state=RANDOM_STATE)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_moons[y_moons == 0, 0], X_moons[y_moons == 0, 1],\n",
    "            c='blue', label='Clase 0', alpha=0.6, edgecolors='k')\n",
    "plt.scatter(X_moons[y_moons == 1, 0], X_moons[y_moons == 1, 1],\n",
    "            c='red', label='Clase 1', alpha=0.6, edgecolors='k')\n",
    "plt.title('Dataset \"Moons\": Â¿Puedes separar esto con una lÃ­nea recta?')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ¤” Una lÃ­nea recta NO puede separar estas dos 'lunas' entrelazadas.\")\n",
    "print(\"   Necesitamos un modelo que dibuje fronteras curvas o escalonadas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1295d27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Â¿CÃ³mo Funciona un Ãrbol de DecisiÃ³n?\n",
    "\n",
    "### El Algoritmo CART (Classification and Regression Trees)\n",
    "\n",
    "1. **Pregunta:** Â¿Feature X > valor umbral?\n",
    "2. **Divide:** Separa los datos en dos grupos (izquierda/derecha)\n",
    "3. **Repite:** Recursivamente hasta que las hojas sean \"puras\" o se alcance un lÃ­mite\n",
    "\n",
    "### ğŸ“ Criterio de DivisiÃ³n: Â¿CÃ³mo elegir la mejor pregunta?\n",
    "\n",
    "| Criterio | FÃ³rmula | InterpretaciÃ³n |\n",
    "|----------|---------|----------------|\n",
    "| **Gini** | $1 - \\sum p_i^2$ | Probabilidad de clasificaciÃ³n incorrecta |\n",
    "| **Entropy** | $-\\sum p_i \\log_2(p_i)$ | Cantidad de \"desorden\" o incertidumbre |\n",
    "\n",
    "**Objetivo:** En cada divisiÃ³n, minimizar la impureza de los nodos hijos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5d8102",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. SimulaciÃ³n: Divide y VencerÃ¡s\n",
    "\n",
    "Entrenaremos un Ã¡rbol en el dataset \"Moons\" y visualizaremos su estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3fcca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Ã¡rbol con profundidad limitada\n",
    "tree_simple = DecisionTreeClassifier(max_depth=3, random_state=RANDOM_STATE)\n",
    "tree_simple.fit(X_moons, y_moons)\n",
    "\n",
    "# Visualizar el Ã¡rbol\n",
    "plt.figure(figsize=(16, 8))\n",
    "plot_tree(tree_simple,\n",
    "          feature_names=['X1', 'X2'],\n",
    "          class_names=['Clase 0', 'Clase 1'],\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('Ãrbol de DecisiÃ³n (max_depth=3)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac8f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunciÃ³n para visualizar frontera de decisiÃ³n\n",
    "def plot_decision_boundary(model, X, y, title):\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4, cmap='RdBu')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='RdBu', edgecolors='k', alpha=0.8)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "\n",
    "\n",
    "# Visualizar frontera\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_decision_boundary(tree_simple, X_moons, y_moons,\n",
    "                       f'Frontera de DecisiÃ³n (Accuracy: {tree_simple.score(X_moons, y_moons):.2%})')\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ“Š Observa cÃ³mo el Ã¡rbol crea fronteras 'escalonadas' (rectangulares).\")\n",
    "print(\"   Cada divisiÃ³n es paralela a uno de los ejes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d0908",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. El Peligro del Overfitting\n",
    "\n",
    "### âš ï¸ Â¿QuÃ© pasa si dejamos crecer el Ã¡rbol sin lÃ­mites?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e83438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_moons, y_moons, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "# Ãrbol SIN restricciones (overfitting)\n",
    "tree_overfit = DecisionTreeClassifier(\n",
    "    max_depth=None, random_state=RANDOM_STATE)\n",
    "tree_overfit.fit(X_train, y_train)\n",
    "\n",
    "# Ãrbol CON restricciones (poda)\n",
    "tree_pruned = DecisionTreeClassifier(\n",
    "    max_depth=4, min_samples_leaf=5, random_state=RANDOM_STATE)\n",
    "tree_pruned.fit(X_train, y_train)\n",
    "\n",
    "# Comparar\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plot_decision_boundary(tree_overfit, X_train, y_train,\n",
    "                       f'âŒ SIN Restricciones\\nTrain: {tree_overfit.score(X_train, y_train):.2%} | Test: {tree_overfit.score(X_test, y_test):.2%}')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plot_decision_boundary(tree_pruned, X_train, y_train,\n",
    "                       f'âœ… CON Poda (max_depth=4)\\nTrain: {tree_pruned.score(X_train, y_train):.2%} | Test: {tree_pruned.score(X_test, y_test):.2%}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d11a7e",
   "metadata": {},
   "source": [
    "> **ğŸ’¡ Pro-Tip: La Regla de la RaÃ­z Cuadrada**\n",
    "> Si tu Ã¡rbol tiene mÃ¡s hojas que $\\sqrt{n}$ (donde n = nÃºmero de muestras), probablemente estÃ¡ memorizando.\n",
    "> \n",
    "> Para 300 muestras: $\\sqrt{300} \\approx 17$ hojas mÃ¡ximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bcae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar nÃºmero de hojas\n",
    "print(f\"ğŸŒ³ Ãrbol SIN restricciones: {tree_overfit.get_n_leaves()} hojas\")\n",
    "print(f\"ğŸŒ³ Ãrbol CON poda: {tree_pruned.get_n_leaves()} hojas\")\n",
    "print(f\"ğŸ“ Regla âˆšn: mÃ¡ximo recomendado â‰ˆ {int(np.sqrt(len(X_train)))} hojas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf005a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. HiperparÃ¡metros Clave\n",
    "\n",
    "| ParÃ¡metro | DescripciÃ³n | Efecto en Overfitting |\n",
    "|-----------|-------------|------------------------|\n",
    "| `max_depth` | Profundidad mÃ¡xima | â†“ profundidad = â†“ overfitting |\n",
    "| `min_samples_split` | MÃ­nimo para dividir un nodo | â†‘ valor = mÃ¡s conservador |\n",
    "| `min_samples_leaf` | MÃ­nimo en hojas finales | Evita hojas con 1-2 ejemplos |\n",
    "| `max_features` | Features por split | AÃ±ade aleatoriedad |\n",
    "| `criterion` | MÃ©trica de pureza | `gini` (default) o `entropy` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff4592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentar con hiperparÃ¡metros\n",
    "depths = [2, 4, 6, 10, None]\n",
    "results = []\n",
    "\n",
    "for depth in depths:\n",
    "    tree = DecisionTreeClassifier(max_depth=depth, random_state=RANDOM_STATE)\n",
    "    tree.fit(X_train, y_train)\n",
    "    results.append({\n",
    "        'max_depth': str(depth),\n",
    "        'Train Acc': tree.score(X_train, y_train),\n",
    "        'Test Acc': tree.score(X_test, y_test),\n",
    "        'N Hojas': tree.get_n_leaves()\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fbe6b0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Caso de Negocio: AprobaciÃ³n de CrÃ©dito\n",
    "\n",
    "Simularemos un dataset de aprobaciÃ³n de crÃ©ditos con variables interpretables.\n",
    "\n",
    "### ğŸ“‚ Diccionario de Datos (Simulado)\n",
    "| Variable | DescripciÃ³n | Unidad |\n",
    "|----------|-------------|--------|\n",
    "| `Ingreso` | Ingreso mensual | Miles de $ |\n",
    "| `Deuda` | Ratio deuda/ingreso | Porcentaje |\n",
    "| `Aprobado` | Â¿Se aprobÃ³ el crÃ©dito? (Target) | 0=No, 1=SÃ­ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56841c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimulaciÃ³n de datos de crÃ©dito\n",
    "np.random.seed(RANDOM_STATE)\n",
    "n = 500\n",
    "\n",
    "ingreso = np.random.normal(50, 20, n)  # Media 50k\n",
    "deuda = np.random.uniform(10, 60, n)    # 10% a 60%\n",
    "\n",
    "# Regla: Aprobar si (Ingreso > 40 Y Deuda < 40) O (Ingreso > 70)\n",
    "aprobado = ((ingreso > 40) & (deuda < 40)) | (ingreso > 70)\n",
    "aprobado = aprobado.astype(int)\n",
    "\n",
    "# AÃ±adir ruido (10% de etiquetas incorrectas)\n",
    "ruido_idx = np.random.choice(n, size=int(n*0.1), replace=False)\n",
    "aprobado[ruido_idx] = 1 - aprobado[ruido_idx]\n",
    "\n",
    "df_credito = pd.DataFrame(\n",
    "    {'Ingreso': ingreso, 'Deuda': deuda, 'Aprobado': aprobado})\n",
    "df_credito.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d851e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Ã¡rbol interpretable\n",
    "X_cred = df_credito[['Ingreso', 'Deuda']]\n",
    "y_cred = df_credito['Aprobado']\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_cred, y_cred, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "tree_credito = DecisionTreeClassifier(\n",
    "    max_depth=4, min_samples_leaf=10, random_state=RANDOM_STATE)\n",
    "tree_credito.fit(X_train_c, y_train_c)\n",
    "\n",
    "# Visualizar Ã¡rbol\n",
    "plt.figure(figsize=(18, 10))\n",
    "plot_tree(tree_credito,\n",
    "          feature_names=['Ingreso', 'Deuda'],\n",
    "          class_names=['Rechazar', 'Aprobar'],\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=11)\n",
    "plt.title('Ãrbol de DecisiÃ³n: AprobaciÃ³n de CrÃ©dito')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0000ce",
   "metadata": {},
   "source": [
    "### ğŸ§  InterpretaciÃ³n para el Regulador\n",
    "\n",
    "El Ã¡rbol genera **reglas explÃ­citas** que podemos explicar:\n",
    "\n",
    "```\n",
    "REGLA 1: Si Ingreso > 70k â†’ APROBAR (clientes premium)\n",
    "REGLA 2: Si Ingreso â‰¤ 70k Y Deuda > 40% â†’ RECHAZAR (alto riesgo)\n",
    "REGLA 3: Si Ingreso â‰¤ 70k Y Deuda â‰¤ 40% Y Ingreso > 40k â†’ APROBAR\n",
    "REGLA 4: Si Ingreso â‰¤ 40k â†’ RECHAZAR (bajo ingreso)\n",
    "```\n",
    "\n",
    "> **âš ï¸ Real-World Warning: Fairness**\n",
    "> En la vida real, debes verificar que las reglas no discriminen por variables protegidas (gÃ©nero, raza, edad). Los Ã¡rboles pueden capturar sesgos histÃ³ricos de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09596f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MÃ©tricas\n",
    "print(\"=\"*50)\n",
    "print(\"ğŸ“Š EVALUACIÃ“N DEL MODELO\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy en Test: {tree_credito.score(X_test_c, y_test_c):.2%}\")\n",
    "print(f\"NÃºmero de hojas: {tree_credito.get_n_leaves()}\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5456f14d",
   "metadata": {},
   "source": [
    "### ğŸ§  Micro-DesafÃ­o: Nueva Solicitud\n",
    "\n",
    "Un cliente con **Ingreso = \\$55k** y **Deuda = 35%** solicita un crÃ©dito.\n",
    "\n",
    "**Pregunta:** Â¿QuÃ© predice el modelo? Sigue las ramas del Ã¡rbol manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072ebd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# ğŸ§  TU TURNO: Micro-DesafÃ­o\n",
    "# ================================\n",
    "nuevo_cliente = pd.DataFrame({'Ingreso': [55], 'Deuda': [35]})\n",
    "prediccion = tree_credito.predict(nuevo_cliente)[0]\n",
    "proba = tree_credito.predict_proba(nuevo_cliente)[0]\n",
    "\n",
    "print(f\"ğŸ“Š PredicciÃ³n: {'âœ… APROBAR' if prediccion == 1 else 'âŒ RECHAZAR'}\")\n",
    "print(f\"ğŸ“Š Probabilidades: Rechazar={proba[0]:.2%}, Aprobar={proba[1]:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd35e98",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Resumen y Siguiente Paso\n",
    "\n",
    "### ğŸ† Resumen de Logros\n",
    "Â¡Felicidades! En este notebook has aprendido:\n",
    "\n",
    "1. **La IntuiciÃ³n:** Un Ã¡rbol es una secuencia de preguntas binarias que divide el espacio.\n",
    "2. **Fronteras Escalonadas:** Los Ã¡rboles crean divisiones paralelas a los ejes.\n",
    "3. **Overfitting:** Sin restricciones, el Ã¡rbol memoriza el ruido (100% train, bajo test).\n",
    "4. **Poda:** `max_depth`, `min_samples_leaf` controlan la complejidad.\n",
    "5. **Interpretabilidad:** Las reglas If-Then son fÃ¡ciles de explicar a stakeholders.\n",
    "\n",
    "### âš ï¸ Limitaciones de un Ãrbol Solo\n",
    "- **Alta varianza:** PequeÃ±os cambios en datos â†’ Ã¡rbol muy diferente.\n",
    "- **Fronteras dentadas:** No captura bien curvas suaves.\n",
    "- **Inestabilidad:** Un outlier puede cambiar toda la estructura.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‘‰ Siguiente Paso\n",
    "Â¿CÃ³mo solucionamos la alta varianza de un Ã¡rbol solo? \n",
    "\n",
    "**Random Forest:** Entrenar muchos Ã¡rboles y promediar sus predicciones. *\"Un experto se equivoca, mil promediados no.\"*\n",
    "\n",
    "*En el siguiente notebook veremos cÃ³mo el Bagging reduce la varianza sin aumentar el sesgo.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
