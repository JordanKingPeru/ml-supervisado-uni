# ğŸ“ Control NÂ° 2: Ãrboles de DecisiÃ³n y MÃ©todos Ensemble

**Curso:** Machine Learning Supervisado - PECD UNI  
**Docente:** Jordan King Rodriguez Mallqui  
**SesiÃ³n:** 02 - Ãrboles de DecisiÃ³n y Ensembles  
**Fecha de entrega:** _07/12/2025_  
**Modalidad:** Individual o en parejas

---

## ğŸ¯ Objetivo

Aplicar y comparar **algoritmos no lineales** (Ãrboles de DecisiÃ³n, Random Forest, Gradient Boosting, SVM, KNN) en un problema de clasificaciÃ³n o regresiÃ³n, demostrando comprensiÃ³n de sus fortalezas, debilidades y el impacto de sus hiperparÃ¡metros.

---

## ğŸ“‹ Instrucciones Generales

### 1. SelecciÃ³n del Dataset

Puedes usar el **mismo dataset del Control NÂ° 1** o elegir uno nuevo de las siguientes opciones:

#### ğŸ”¹ OpciÃ³n A: Datasets Sugeridos (ClasificaciÃ³n)

| Dataset | DescripciÃ³n | Enlace |
|---------|-------------|--------|
| **Telco Churn** | PredicciÃ³n de fuga de clientes | [Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn) |
| **Credit Card Fraud** | DetecciÃ³n de fraude | [Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) |
| **Mushroom** | ClasificaciÃ³n comestible/venenoso | [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/mushroom) |
| **Breast Cancer** | DiagnÃ³stico de cÃ¡ncer | [Scikit-Learn](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset) |
| **Customer Segmentation** | SegmentaciÃ³n de clientes | [Kaggle](https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python) |

#### ğŸ”¹ OpciÃ³n B: Datasets Sugeridos (RegresiÃ³n)

| Dataset | DescripciÃ³n | Enlace |
|---------|-------------|--------|
| **Boston Housing** | Precio de viviendas | [Kaggle](https://www.kaggle.com/datasets/vikrishnan/boston-house-prices) |
| **Bike Sharing** | Demanda de bicicletas | [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset) |
| **Energy Efficiency** | Consumo energÃ©tico de edificios | [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/energy+efficiency) |
| **Insurance Charges** | PredicciÃ³n de costos mÃ©dicos | [Kaggle](https://www.kaggle.com/datasets/mirichoi0218/insurance) |

#### ğŸ”¹ OpciÃ³n C: Dataset Propio

Requisitos:
- Disponible en **repositorio pÃºblico** (Kaggle, UCI, OpenML, GitHub, etc.)
- Al menos **500 registros** y **5 features**
- Problema de **clasificaciÃ³n** o **regresiÃ³n**
- Enlace de descarga incluido (notebook replicable)

---

## ğŸ“¦ Entregables

### Notebook Jupyter con las siguientes secciones:

#### **1. IntroducciÃ³n y Contexto** (5 pts)
- DescripciÃ³n breve del problema
- JustificaciÃ³n de por quÃ© un modelo no lineal podrÃ­a ser Ãºtil

#### **2. Carga y Preprocesamiento** (10 pts)
- Carga del dataset
- Pipeline de preprocesamiento (reutilizar lo aprendido en SesiÃ³n 1)
- DivisiÃ³n train/test correcta

#### **3. Entrenamiento de Modelos** (30 pts)

Entrenar al menos **4 de los siguientes modelos**:

| Modelo | Clase en Scikit-Learn |
|--------|----------------------|
| Ãrbol de DecisiÃ³n | `DecisionTreeClassifier` / `DecisionTreeRegressor` |
| Random Forest | `RandomForestClassifier` / `RandomForestRegressor` |
| Gradient Boosting | `GradientBoostingClassifier` / `GradientBoostingRegressor` |
| XGBoost | `XGBClassifier` / `XGBRegressor` |
| SVM | `SVC` / `SVR` |
| KNN | `KNeighborsClassifier` / `KNeighborsRegressor` |

Para cada modelo:
- Entrenar con hiperparÃ¡metros por defecto
- Documentar brevemente quÃ© hace el algoritmo

#### **4. ComparaciÃ³n de Modelos** (20 pts)
- Tabla comparativa con mÃ©tricas de todos los modelos
- GrÃ¡fico de barras comparando rendimiento
- AnÃ¡lisis: Â¿CuÃ¡l modelo tiene mejor desempeÃ±o? Â¿Por quÃ©?

#### **5. Ajuste Manual de HiperparÃ¡metros** (20 pts)

Seleccionar el **mejor modelo** de la comparaciÃ³n y realizar:
- Probar **manualmente** al menos **3 configuraciones diferentes** de hiperparÃ¡metros
- **Justificar** por quÃ© elegiste esos valores (basÃ¡ndote en la teorÃ­a vista en clase)
- Comparar resultados de cada configuraciÃ³n
- Reportar mejora obtenida (si la hay)

> **ğŸ“ Nota:** En la siguiente sesiÃ³n veremos tÃ©cnicas automÃ¡ticas como `GridSearchCV` y `RandomizedSearchCV`. Por ahora, el objetivo es que entiendas el **efecto de cada hiperparÃ¡metro** mediante experimentaciÃ³n manual.

Ejemplo de hiperparÃ¡metros a explorar:

| Modelo | HiperparÃ¡metros Sugeridos |
|--------|---------------------------|
| Decision Tree | `max_depth`, `min_samples_split`, `min_samples_leaf` |
| Random Forest | `n_estimators`, `max_depth`, `max_features` |
| Gradient Boosting | `n_estimators`, `learning_rate`, `max_depth` |
| SVM | `C`, `kernel`, `gamma` |
| KNN | `n_neighbors`, `weights`, `metric` |

#### **6. Interpretabilidad** (10 pts)
- Para modelos basados en Ã¡rboles: **Feature Importance**
- VisualizaciÃ³n del Ã¡rbol (si aplica, con `plot_tree` o similar)
- InterpretaciÃ³n: Â¿QuÃ© variables son mÃ¡s importantes para el modelo?

#### **7. Conclusiones** (5 pts)
- Â¿QuÃ© modelo recomiendas para producciÃ³n y por quÃ©?
- Trade-offs observados (accuracy vs interpretabilidad, tiempo de entrenamiento, etc.)
- PrÃ³ximos pasos sugeridos

---

## âš ï¸ Criterios de EvaluaciÃ³n

| Criterio | Puntos | DescripciÃ³n |
|----------|--------|-------------|
| **Reproducibilidad** | 10 | Notebook ejecutable de principio a fin |
| **Pipeline correcto** | 10 | Preprocesamiento dentro del pipeline, sin data leakage |
| **Modelos entrenados** | 30 | Al menos 4 modelos diferentes correctamente implementados |
| **ComparaciÃ³n justa** | 20 | MÃ©tricas apropiadas, mismo split para todos |
| **Tuning de hiperparÃ¡metros** | 20 | ExperimentaciÃ³n manual con justificaciÃ³n |
| **Interpretabilidad** | 10 | Feature importance y/o visualizaciÃ³n del Ã¡rbol |
| **TOTAL** | **100** | |

---

## ğŸš« Errores que Penalizan

- âŒ Comparar modelos con diferentes splits de datos (-10 pts)
- âŒ No usar `random_state` en modelos y splits (-5 pts)
- âŒ No justificar los cambios de hiperparÃ¡metros (-10 pts)
- âŒ Notebook que no ejecuta de principio a fin (-20 pts)
- âŒ Solo entrenar 2 modelos o menos (-15 pts)
- âŒ No incluir Feature Importance cuando aplica (-5 pts)

---

## ğŸ“¤ Formato de Entrega

1. **Archivo:** `Control02_Apellido_Nombre.ipynb`
2. **Plataforma:** [Canvas](https://canvas.instructure.com/courses/12906015)

### Estructura sugerida del notebook:

```
1. TÃ­tulo y datos del alumno
2. IntroducciÃ³n
3. Carga y Preprocesamiento
4. Entrenamiento de Modelos (4+ modelos)
5. ComparaciÃ³n y AnÃ¡lisis
6. Ajuste Manual de HiperparÃ¡metros
7. Interpretabilidad (Feature Importance)
8. Conclusiones
9. Referencias
```

---

## ğŸ’¡ Tips para un Buen Trabajo

1. **Reutiliza tu Pipeline:** El preprocesamiento del Control 1 puede servir aquÃ­
2. **Usa `cross_val_score`:** Para una comparaciÃ³n mÃ¡s robusta
3. **Cuidado con el tiempo:** Algunos modelos (SVM, GridSearch extenso) pueden tardar mucho
4. **Documenta tus decisiones:** Â¿Por quÃ© elegiste esos rangos de hiperparÃ¡metros?
5. **Visualiza:** Un grÃ¡fico vale mÃ¡s que mil nÃºmeros

### CÃ³digo de Referencia: ComparaciÃ³n RÃ¡pida

```python
from sklearn.model_selection import cross_val_score

modelos = {
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'KNN': KNeighborsClassifier()
}

resultados = []
for nombre, modelo in modelos.items():
    scores = cross_val_score(modelo, X_train, y_train, cv=5, scoring='accuracy')
    resultados.append({
        'Modelo': nombre,
        'CV Mean': scores.mean(),
        'CV Std': scores.std()
    })

pd.DataFrame(resultados).sort_values('CV Mean', ascending=False)
```

---

## ğŸ“š Recursos de Apoyo

### ğŸ“‚ Repositorio del Curso
Todo el material estÃ¡ disponible en:

ğŸ”— **[https://github.com/JordanKingPeru/ml-supervisado-uni](https://github.com/JordanKingPeru/ml-supervisado-uni)**

### ğŸ““ Notebooks de la SesiÃ³n 2
- `00a_Arboles_Decision_Intro.ipynb` - Fundamentos de Ãrboles de DecisiÃ³n
- `00b_Random_Forest_Intro.ipynb` - Random Forest y Bagging
- `00c_Gradient_Boosting_Intro.ipynb` - Gradient Boosting
- `00d_SVM_Intro.ipynb` - Support Vector Machines
- `00e_KNN_Intro.ipynb` - K-Nearest Neighbors
- `01_Algoritmos_No_Lineales.ipynb` - ComparaciÃ³n de algoritmos
- `02_Arena_Combate.ipynb` - Competencia de modelos

### ğŸ”— DocumentaciÃ³n Oficial
- [Decision Trees - Scikit-Learn](https://scikit-learn.org/stable/modules/tree.html)
- [Random Forest - Scikit-Learn](https://scikit-learn.org/stable/modules/ensemble.html#forest)
- [Gradient Boosting - Scikit-Learn](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting)
- [SVM - Scikit-Learn](https://scikit-learn.org/stable/modules/svm.html)
- [KNN - Scikit-Learn](https://scikit-learn.org/stable/modules/neighbors.html)
- [GridSearchCV - Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) *(referencia para la siguiente sesiÃ³n)*

### ğŸ“‹ Cheatsheet de HiperparÃ¡metros
Consulta el archivo `recursos/cheatsheets/hyperparameters_cheatsheet.md` del repositorio.

---

## â“ Preguntas Frecuentes

**P: Â¿Puedo usar el mismo dataset del Control 1?**  
R: SÃ­, de hecho es recomendable para comparar modelos lineales vs no lineales.

**P: Â¿Es obligatorio usar XGBoost?**  
R: No, pero si lo usas ganas puntos extra por exploraciÃ³n (+5 pts bonus).

**P: Â¿QuÃ© hago si no sÃ© quÃ© valores probar para los hiperparÃ¡metros?**  
R: Revisa los notebooks de clase y el cheatsheet de hiperparÃ¡metros. Empieza con valores pequeÃ±os y ve aumentando.

**P: Â¿Puedo usar LightGBM o CatBoost?**  
R: SÃ­, se consideran como alternativas vÃ¡lidas a Gradient Boosting.

**P: Â¿Es necesario visualizar todos los Ã¡rboles?**  
R: No, solo visualiza uno representativo (ej: un Ã¡rbol del Random Forest o el Decision Tree simple).

---

## ğŸ† Bonus Points (+10 pts mÃ¡ximo)

- **+5 pts:** Usar XGBoost, LightGBM o CatBoost
- **+3 pts:** Incluir curvas de aprendizaje (learning curves)
- **+2 pts:** AnÃ¡lisis de overfitting con diferentes `max_depth`

---

Â¡Ã‰xitos! ğŸš€ğŸŒ³
